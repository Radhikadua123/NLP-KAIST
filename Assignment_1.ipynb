{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KAIST_AI605_Assignment_1_Radhika_Dua_20204824.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5fcdb6ba543a4022a825cc9c33092168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a61d4b05413548bb959f19cbe18ec4e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3db305e73b944c1190cb39401492d900",
              "IPY_MODEL_052f92a0543b48669c29d809d35bbd93"
            ]
          }
        },
        "a61d4b05413548bb959f19cbe18ec4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3db305e73b944c1190cb39401492d900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa24a06ade054d82a74faf06ce48b9bd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d9d984a928342ed9f0e4cf1501c7895"
          }
        },
        "052f92a0543b48669c29d809d35bbd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ed78d9b8533470ca39833400f260d1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 120kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0827c66b5d24223a48255e6889796ea"
          }
        },
        "aa24a06ade054d82a74faf06ce48b9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d9d984a928342ed9f0e4cf1501c7895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ed78d9b8533470ca39833400f260d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0827c66b5d24223a48255e6889796ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfc896e651a241f3a5358895bb723e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4888cc20efeb46d597e602b1eae7a58d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f9db44e9f7c0476cbe9ac8c990df4ed4",
              "IPY_MODEL_9efc1d1874ef414080c15a060fe7f98b"
            ]
          }
        },
        "4888cc20efeb46d597e602b1eae7a58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9db44e9f7c0476cbe9ac8c990df4ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6850fd982a3b4cca8fb90a8c5b0d0665",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a484c6673db644769832fa3e55c4c0be"
          }
        },
        "9efc1d1874ef414080c15a060fe7f98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_683c4455d9a6409fa3232f97f621bc7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 33.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b38a058067349cfa293dc9ff2fcd760"
          }
        },
        "6850fd982a3b4cca8fb90a8c5b0d0665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a484c6673db644769832fa3e55c4c0be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "683c4455d9a6409fa3232f97f621bc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b38a058067349cfa293dc9ff2fcd760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0043719545de4b0b87be69b56e6b7404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0afaf4f3fda4188af044dc97378f66e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56a75348d52d46b0818c10904a9556d7",
              "IPY_MODEL_ebed889def87402d958c7f904259e82e"
            ]
          }
        },
        "e0afaf4f3fda4188af044dc97378f66e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56a75348d52d46b0818c10904a9556d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71a503fbda8645c58f30ad9e2b3e61ab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73e203b59cde424eab1d986be21d0940"
          }
        },
        "ebed889def87402d958c7f904259e82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e23c8eba6724fe9bdac9dfae0ccfeea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7092c98c6ee348289c2dc8e3977f7a29"
          }
        },
        "71a503fbda8645c58f30ad9e2b3e61ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73e203b59cde424eab1d986be21d0940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e23c8eba6724fe9bdac9dfae0ccfeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7092c98c6ee348289c2dc8e3977f7a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72e1fb5e4f574da6ba9c30bd7e6f54bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aeab2f15d3eb4ea992be133ad03a0c4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b89569f48e434c7b9444a60b3705c672",
              "IPY_MODEL_e196344fc50e4347a8889f501970cefc"
            ]
          }
        },
        "aeab2f15d3eb4ea992be133ad03a0c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b89569f48e434c7b9444a60b3705c672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b2044b467ea4ef7901d17e652ecfada",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7581f3177bf4e2895ab544936c77f52"
          }
        },
        "e196344fc50e4347a8889f501970cefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6193f5ffc95447c2a52de28d1ddb21bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.35kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aa32df0815a4424b520f400c5a0263e"
          }
        },
        "5b2044b467ea4ef7901d17e652ecfada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7581f3177bf4e2895ab544936c77f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6193f5ffc95447c2a52de28d1ddb21bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aa32df0815a4424b520f400c5a0263e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5c31ab0a2004e09850f368bce424adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_433efc1bc42b4391a57492e52482337d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a29299804594b4e8c01a9552eca71fe",
              "IPY_MODEL_d6354fb3f56e4755a226b3f568cd51a7"
            ]
          }
        },
        "433efc1bc42b4391a57492e52482337d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a29299804594b4e8c01a9552eca71fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1be4668d4ffe40df9f41ebccab5f8610",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f9ff0e9fd4b4cedb8abffd2f496c4ec"
          }
        },
        "d6354fb3f56e4755a226b3f568cd51a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e11a5dba97474cd3860c6163b5e7c096",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 51.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b51bce2b054248909a208b20c5461dd4"
          }
        },
        "1be4668d4ffe40df9f41ebccab5f8610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f9ff0e9fd4b4cedb8abffd2f496c4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e11a5dba97474cd3860c6163b5e7c096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b51bce2b054248909a208b20c5461dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGnNWI1lRy_"
      },
      "source": [
        "# KAIST AI605 Assignment 1: Text Classification with RNNs\n",
        "Authors: Hyeong-Gwon Hong (honggudrnjs@kaist.ac.kr) and Minjoon Seo (minjoon@kaist.ac.kr)\n",
        "\n",
        "**Due Date:** March 31 (Wed) 11:00pm, 2021\n",
        "\n",
        "## Assignment Objectives\n",
        "- Verify theoretically and empirically why gating mechanism (LSTM, GRU) helps in Recurrent Neural Networks (RNNs)\n",
        "- Design an LSTM-based text classification model from scratch using PyTorch.\n",
        "- Apply the classification model to a popular classification task, Stanford Sentiment Treebank v2 (SST-2).\n",
        "- Achieve higher accuracy by applying common machine learning strategies, including Dropout.\n",
        "- Utilize pretrained word embedding, GloVe, to leverage self-supervision over a large text corpus.\n",
        "- (Bonus) Use Hugging Face library (`transformers`) to leverage self-supervision via large language models.\n",
        "\n",
        "## Your Submission\n",
        "Your submission will be a link to a CoLab notebook that has all written answers and is fully executable. Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own.\n",
        "\n",
        "## Grading\n",
        "The entire assignment is out of 100 points. There are two bonus questions with 10 points each.\n",
        "\n",
        "\n",
        "## Environment\n",
        "You will only use Python 3.7 and PyTorch 1.8, which is already available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGi1tcFWb50z",
        "outputId": "cbb722a8-f9eb-4dd7-fd27-2b344be2b983"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYxEp1XMpxem",
        "outputId": "b622f2c0-cb76-40e6-ae18-8d8585588ef6"
      },
      "source": [
        "from platform import python_version\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "print(\"python\", python_version())\n",
        "print(\"torch\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python 3.7.10\n",
            "torch 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB7xyzIgnnkA"
      },
      "source": [
        "## 1. Limitations of Vanilla RNNs\n",
        "In Lecture 04 and 05, we saw how RNNs suffer from exploding or vanishing gradients. We mathematically showed that, if the recurrent relation is\n",
        "$$ \\textbf{h}_t = \\sigma (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}) $$\n",
        "then\n",
        "$$ \\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{h}_{t-1}} = \\text{diag}(\\sigma' (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}))\\textbf{V}$$\n",
        "so\n",
        "$$\\frac{\\partial \\textbf{h}_T}{\\partial \\textbf{h}_1} \\propto \\textbf{V}^{T-1}$$\n",
        "which means this term will be very close to zero if the norm of $\\bf{V}$ is smaller than 1 and really big otherwise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhzyD0wsBvdT"
      },
      "source": [
        "\n",
        "**Problem 1.1** *(10 points)* Explain how exploding gradient can be mitigated if we use gradient clipping.\n",
        "\n",
        "<font color='blue'> **Solution:** Gradient clipping is based on a simple idea. If the gradient exceeds some threshold $c$, then gradient clipping makes it equal to the threshold $c$.\n",
        "Gradient clipping normalizes the gradient vector and rescales the gradient values when they exceed a threshold in the following way:\n",
        "$$g \\leftarrow c * \\frac{g}{||g||}$$\n",
        "\n",
        "<font color='blue'>The above expression ensures that the gradients have the norm atmost c. If we encounter the problem of exploding gradients, then with gradient clipping we can reduce the large descent step making training stable. Specifically, the values of the error gradient are checked against a threshold value and clipped or set to that threshold value if the error gradient exceeds the threshold.<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3queOZwBzSc"
      },
      "source": [
        "**Problem 1.2** *(10 points)* Explain how vanishing gradient can be mitigated if we use LSTM. See the Lecture 04 and 05 slides for the definition of LSTM.\n",
        "\n",
        "<font color='blue'>The cell state gradient is an additive function made up from four elements denoted as shown in the equation below. \n",
        " \\begin{aligned} \\frac{\\partial c_{t}}{\\partial c_{t-1}}=& \\sigma^{\\prime}\\left(W_{f} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\cdot W_{f} \\cdot o_{t-1} \\otimes \\tanh ^{\\prime}\\left(c_{t-1}\\right) \\cdot c_{t-1} \\\\ &+f_{t} \\\\ &+\\sigma^{\\prime}\\left(W_{i} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\cdot W_{i} \\cdot o_{t-1} \\otimes \\tanh ^{\\prime}\\left(c_{t-1}\\right) \\cdot \\tilde{c}_{t} \\\\ &+\\sigma^{\\prime}\\left(W_{c} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\cdot W_{c} \\cdot o_{t-1} \\otimes \\tanh ^{\\prime}\\left(c_{t-1}\\right) \\cdot i_{t} \\end{aligned}\n",
        "<font color='blue'>\n",
        "This additive property enables better balancing of gradient values during backpropagation. The LSTM updates and balances the values of the four components making it more likely the additive expression does not vanish.<font>\n",
        "\n",
        "<font color='blue'> There are primarily two factors that affect the magnitude of gradients. These are the weights and the activation functions.\n",
        "If either of these factors is smaller than 1, then the gradients may vanish in time (or otherwise known as the gradient descent problem). If either of these factors is larger than 1, then the gradients may explode (or otherwise known as the exploding gradient problem). \n",
        "In the recurrency of the LSTM the activation function is the identity function with a derivative of 1.0. So, the backpropagated gradient neither vanishes or explodes.\n",
        "The effective weight of the recurrency is equal to the forget gate activation. So, if the forget gate is on (activation close to 1.0), then the gradient does not vanish. Since the forget gate activation is never  >1.0 , the gradient can't explode either.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0AmoAT3wA1J"
      },
      "source": [
        "## 2. Creating Vocabulary from Training Data\n",
        "Creating the vocabulary is the first step for every natural language processing model. In this section, you will use Stanford Sentiment Treebank v2, a popular dataset for sentiment classification, to create your vocabulary.\n",
        "\n",
        "### Obtaining SST-2 via GLUE\n",
        "General Language Understanding Evaluation (GLUE) benchmark is a collection of tools for evaluating the performance of models across a diverse set of existing natural language understanding (NLU) tasks. From the GLUE website (https://gluebenchmark.com/), you can access to the GLUE paper (https://openreview.net/pdf?id=rJ4km2R5t7) and the GitHub repository for GLUE baselines (Reference : https://github.com/nyu-mll/GLUE-baselines) .\n",
        "\n",
        "You can download SST-2 dataset by following the steps below:\n",
        "\n",
        "1. Clone GitHub repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK0S_VTJxds4",
        "outputId": "c86e745c-f429-45d6-ae93-fad500dad84b"
      },
      "source": [
        "!git clone https://github.com/nyu-mll/GLUE-baselines.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GLUE-baselines'...\n",
            "remote: Enumerating objects: 891, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 891 (delta 1), reused 2 (delta 0), pack-reused 886\u001b[K\n",
            "Receiving objects: 100% (891/891), 1.48 MiB | 5.33 MiB/s, done.\n",
            "Resolving deltas: 100% (610/610), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8eWbt2yxb3H"
      },
      "source": [
        "2. Download dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82lvEkrW7ElS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6drFIvgxxjgI",
        "outputId": "70d9c470-15eb-45ad-c6e4-3ec98914b72f"
      },
      "source": [
        "%cd GLUE-baselines/\n",
        "!python download_glue_data.py --data_dir glue_data --tasks SST"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GLUE-baselines/GLUE-baselines\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAVQyYWkxib6"
      },
      "source": [
        "Your training, dev, and test data can be found at `glue_data/SST-2`. Note that each file is in a tsv format, where the first column is the sentence and the second column is the label (either 0 or 1, where 1 means positive review). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRh3BQ_TrGf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b960e935-1f2d-4726-cd41-391c5f4086bf"
      },
      "source": [
        "# Splitting the training dataset to train, val set and using validation data for testing\n",
        "tsv_read = pd.read_csv('glue_data/SST-2/train.tsv', sep='\\t')[:65000]\n",
        "val_tsv_read = pd.read_csv('glue_data/SST-2/train.tsv', sep='\\t')[65000:]\n",
        "test_tsv_read = pd.read_csv('glue_data/SST-2/dev.tsv', sep='\\t')\n",
        "print(len(tsv_read),len(val_tsv_read), len(test_tsv_read))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65000 2349 872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "_FcED9Z-wVnF",
        "outputId": "0762e921-70d6-4002-d1cc-a3233ad6d420"
      },
      "source": [
        "val_tsv_read.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65000</th>\n",
              "      <td>content merely to lionize its title character ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65001</th>\n",
              "      <td>a subtle , humorous , illuminating study</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65002</th>\n",
              "      <td>a solid and refined piece of moviemaking</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65003</th>\n",
              "      <td>as padded as allen 's jelly belly</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65004</th>\n",
              "      <td>having so much fun</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  label\n",
              "65000  content merely to lionize its title character ...      0\n",
              "65001          a subtle , humorous , illuminating study       1\n",
              "65002          a solid and refined piece of moviemaking       1\n",
              "65003                 as padded as allen 's jelly belly       0\n",
              "65004                                having so much fun       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s0T6qk6x78s"
      },
      "source": [
        "**Problem 2.1** *(10 points)* Using space tokenizer, create the vocabulary for the training data and report the vocabulary size here. Make sure that you add an `UNK` token to the vocabulary to account for words (during inference time) that you haven't seen. See below for an example with a short text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETHJ0J0pgYI"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 2.1}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUuk0OFQOEZa",
        "outputId": "4d465001-7472-4a33-9779-1f8d0e270836"
      },
      "source": [
        "# Space tokenization\n",
        "# tsv_read['sentence'] = tsv_read['sentence'].str.lower()\n",
        "tsv_read['sentence'] = tsv_read['sentence']\n",
        "text = list(tsv_read['sentence'])\n",
        "tokens = []\n",
        "for i in range(len(text)):\n",
        "  temp_tokens = text[i].split(\" \")\n",
        "  # temp_tokens = re.findall(r\"[\\w']+|[.,!?;-_#%()<>()#:'@%#$]\",text[i])\n",
        "  temp_tokens1 = list(list(filter(('').__ne__, temp_tokens))) # removing \"''\" from the tokens\n",
        "  tokens.extend(temp_tokens1)\n",
        "\n",
        "print(\"Number of reviews in the training dataset:\", len(text))\n",
        "print(\"Total number of tokens in the reviews from training dataset:\", len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews in the training dataset: 65000\n",
            "Total number of tokens in the reviews from training dataset: 612161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iCTn95_pK7i",
        "outputId": "d0889bf4-8c49-458e-eb82-79f7405cfc45"
      },
      "source": [
        "# Constructing vocabulary from train data using space tokenizer and adding 'UNK' token\n",
        "vocab = ['UNK'] + ['PAD'] + list(set(tokens))\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "print(\"Vocabulary size:\", len(vocab))\n",
        "print(word2id[\"UNK\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 14799\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwzejthdp5rw"
      },
      "source": [
        "<font color='blue'> In above cells, I created the vocabulary for the training data using space tokenizer. The vocabulary size is **14799** words in this case.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVv57zy1OZ0"
      },
      "source": [
        "**Problem 2.2** *(10 points)* Using all words in the training data will make the vocabulary very big. Reduce its size by only including words that occur at least 2 times. How does the size of the vocabulary change?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyjLcTUdpt5b"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 2.2}}$\n",
        "<font color='blue'> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5p3xck60Qxo",
        "outputId": "069fe7a6-e8bf-4b54-8f1e-7fa6cf63e5b1"
      },
      "source": [
        "# Using the tokens generated in Problem 2.1 \n",
        "print(\"Number of reviews in the training dataset:\", len(text))\n",
        "print(\"Number of tokens in the reviews from training dataset:\", len(tokens))\n",
        "\n",
        "# Finding the frequency of occurence of each token in the reviews\n",
        "token_counts = {}\n",
        "tokens_final = []\n",
        "\n",
        "for token in tokens:\n",
        "    if token in token_counts:\n",
        "        token_counts[token] += 1\n",
        "    else:\n",
        "        token_counts[token] = 1\n",
        "\n",
        "# Including only those tokens that occured atleast 2 times\n",
        "for token in token_counts.keys():\n",
        "    if token_counts[token] >= 2:\n",
        "        tokens_final.append(token)\n",
        "\n",
        "print(\"\\nNumber of tokens that occured atleast 2 times in the training data :\", len(tokens_final))      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews in the training dataset: 65000\n",
            "Number of tokens in the reviews from training dataset: 612161\n",
            "\n",
            "Number of tokens that occured atleast 2 times in the training data : 14259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRwYp_1WzsSc",
        "outputId": "ee18d23c-3750-42be-c900-0f8dbd3257c4"
      },
      "source": [
        "# Constructing vocabulary using space tokenizer and adding 'UNK' token\n",
        "vocab = ['UNK'] + ['PAD'] + list(set(tokens_final))\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "print(\"Vocabulary size after including tokens with frequency of atleast 2\", len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size after including tokens with frequency of atleast 2 14261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C78Lt58qZqK"
      },
      "source": [
        "<font color='blue'> In above cells, I created the vocabulary for the training data using space tokenizer. Vocabulary size after including tokens that occur atleast two times in the dataset is **14261** words. This vocabulary has **538 words less** then the vocabulary with all words included. Although, there is not a significant reduction in the size of the vocabulary, using words which occur atleast two times in training dataset is helpful as there are fewmany words which are useless/typos and including them in the vocabulary is not important. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDQbmM3W2Im3"
      },
      "source": [
        "## 3. Text Classification Baselines\n",
        "\n",
        "You can now use the vocabulary constructed from the training data to create an embedding matrix. You will use the embedding matrix to map each input sequence of tokens to a list of embedding vectors. One of the simplest baseline is to go through one layer of neural network and then average the outputs, and finally classify the average embedding: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51TZgipBO-zl",
        "outputId": "75cef8cf-c585-4684-ce91-04e76dfa69cf"
      },
      "source": [
        "def tokenization(text): \n",
        "  tokens_per_sent = []\n",
        "  input_ids = []\n",
        "  for i in range(len(text)):\n",
        "    temp_tokens = text[i].split(\" \")\n",
        "    temp_tokens = list(list(filter(('').__ne__, temp_tokens))) # removing \"''\" from the tokens\n",
        "    tokens_per_sent.append(temp_tokens)\n",
        "    tokens_id = [word2id[word] if word in word2id else 0 for word in temp_tokens]\n",
        "    input_ids.append(tokens_id)\n",
        "  return tokens_per_sent, input_ids\n",
        "\n",
        "text = tsv_read['sentence']\n",
        "labels = list(tsv_read['label'])\n",
        "text = list(text.str.lower())\n",
        "tokens, token_ids = tokenization(text)\n",
        "print(\"Number of reviews in the training dataset:\", len(text))\n",
        "\n",
        "val_text = val_tsv_read['sentence']\n",
        "val_labels = list(val_tsv_read['label'])\n",
        "val_text = list(val_text.str.lower())\n",
        "val_tokens, val_token_ids = tokenization(val_text)\n",
        "print(\"Number of reviews in the validation dataset:\", len(val_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews in the training dataset: 65000\n",
            "Number of reviews in the validation dataset: 2349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vUmITCFqMit"
      },
      "source": [
        "# One layer, average pooling and classification\n",
        "class Baseline(nn.Module):\n",
        "  def __init__(self, d):\n",
        "    super(Baseline, self).__init__()\n",
        "    self.embedding = nn.Embedding(len(vocab), d)\n",
        "    self.layer = nn.Linear(d, d, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.class_layer = nn.Linear(d, 2, bias=True)\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    emb = self.embedding(input_tensor)\n",
        "    out = self.relu(self.layer(emb))\n",
        "    avg = out.mean(1)\n",
        "    logits = self.class_layer(avg)\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UuMWCG9YNs"
      },
      "source": [
        "Now we will compute the loss, which is the negative log probability of the input text's label being the target label (`1`), which in fact turns out to be equivalent to the cross entropy (https://en.wikipedia.org/wiki/Cross_entropy) between the probability distribution and a one-hot distribution of the target label (note that we use `logits` instead of `softmax(logits)` as the input to the cross entropy, which allow us to avoid numerical instability). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nxgYNzQqaPJ"
      },
      "source": [
        "# cel = nn.CrossEntropyLoss()\n",
        "# label = torch.LongTensor([1]) # The ground truth label for \"hi world!\" is positive.\n",
        "# loss = cel(logits, label) # Loss, a.k.a L\n",
        "# print(loss)\n",
        "# print(logits, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKR99jZ2-wZW"
      },
      "source": [
        "Once we have the loss defined, only one step remains! We compute the gradients of parameters with respective to the loss and update. Fortunately, PyTorch does this for us in a very convenient way. Note that we used only example to update the model, which is basically a Stochastic Gradient Descent (SGD) with minibatch size of 1. A recommended minibatch size in this exercise is at least 16. It is also recommended that you reuse your training data at least 10 times (i.e. 10 *epochs*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8JjhgQ071d6"
      },
      "source": [
        "# optimizer = torch.optim.SGD(baseline.parameters(), lr=0.1)\n",
        "# optimizer.zero_grad() # reset process\n",
        "# loss.backward() # compute gradients\n",
        "# optimizer.step() # update parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8M0fhFf_LbG"
      },
      "source": [
        "Once you have done this, all weight parameters will have `grad` attributes that contain their gradients with respect to the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpwOavsD8mpn"
      },
      "source": [
        "# print(baseline.layer.weight.grad) # dL/dw of weights in the linear layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-O9D26U_aEB"
      },
      "source": [
        "**Problem 3.1** *(10 points)* Properly train this average-pooling baseline model on SST-2 and report the model's accuracy on the dev data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hITF5wRhtsqu"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 3.1}}$\n",
        "<font color='blue'> Training the model on 65000 samples of train set; validating using remaining samples of train set; testing it on the dev set. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZQ4yT4aKuKa"
      },
      "source": [
        "# result_path = '/home/radhika/radhika_77/data/nlp/models/'\n",
        "result_path = '/content/drive/MyDrive/nlp/'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "softmax = nn.Softmax(1) \n",
        "\n",
        "def train(model, data, labels, val_data, val_labels, num_epochs = 12, file = None):    \n",
        "    if (file != None):\n",
        "      best_file = os.path.join(result_path, file)\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "    best_acc = 0\n",
        "    best_acc_epoch = 0\n",
        "    \n",
        "    train_loss=[]\n",
        "    train_acc=[]\n",
        "    val_loss = []\n",
        "    val_acc=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      epoch_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      epoch_acc = 0\n",
        "      for i in range(len(labels)):\n",
        "          input_tensor = torch.LongTensor([data[i]])\n",
        "          label = torch.LongTensor([labels[i]])\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          logits = model(input_tensor)\n",
        "          loss = criterion(logits, label)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          _, predicted = torch.max(logits.data, 1)\n",
        "          total += label.size(0)\n",
        "          correct += (predicted == label).sum().item()\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "      epoch_acc = (100 * correct / total)\n",
        "      train_loss.append(round((epoch_loss / len(labels)), 2))\n",
        "      train_acc.append(round((epoch_acc),2))\n",
        "\n",
        "      with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_epoch_loss = 0\n",
        "            val_total = 0\n",
        "            val_correct = 0\n",
        "            epoch_val_acc = 0\n",
        "            for i in range(len(val_labels)):\n",
        "                input_tensor, label = val_data[i], val_labels[i]\n",
        "                input_tensor = torch.LongTensor([input_tensor])\n",
        "                label = torch.LongTensor([label])\n",
        "                logits = model(input_tensor)\n",
        "                loss = criterion(logits, label)\n",
        "                _, predicted = torch.max(logits.data, 1)\n",
        "                val_total += label.size(0)\n",
        "                val_correct += (predicted == label).sum().item()\n",
        "                val_epoch_loss += loss.item()\n",
        "\n",
        "            val_loss.append(round((val_epoch_loss / len(val_labels)),2))\n",
        "            epoch_val_acc = (100 * val_correct / val_total)\n",
        "            val_acc.append(round((epoch_val_acc),2))\n",
        "      print(\"epoch {}: Training Loss- {:.2f} , Val Loss- {:.2f} , Training Acc- {:.2f}, Val Acc- {:.2f}\".format(epoch, epoch_loss, val_epoch_loss, epoch_acc, epoch_val_acc))\n",
        "      if (epoch_val_acc >= best_acc):\n",
        "            best_acc = epoch_val_acc\n",
        "            best_acc_epoch = epoch\n",
        "            if (file!=None):\n",
        "              torch.save(model.state_dict(), best_file)         \n",
        "      if (epoch == num_epochs - 1):\n",
        "        print(\"Best accuracy at epoch: {}\".format(best_acc_epoch))\n",
        "    return train_loss, train_acc, val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qw-CSeHKuKa"
      },
      "source": [
        "def test(model, data, labels, file = None):\n",
        "    if (file!=None):\n",
        "      best_file = os.path.join(result_path, file)\n",
        "      model.load_state_dict(torch.load(best_file))\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        test_total = 0\n",
        "        test_correct = 0\n",
        "        test_loss = 0\n",
        "        test_accuracy = 0\n",
        "        for i in range(len(labels)):\n",
        "            input_tensor, label = data[i],  labels[i]\n",
        "            input_tensor = torch.LongTensor([input_tensor])\n",
        "            label = torch.LongTensor([label])\n",
        "            logits = model(input_tensor)\n",
        "            loss = criterion(logits, label)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            test_total += label.size(0)\n",
        "            test_correct += (predicted == label).sum().item()\n",
        "            test_loss += loss.item()\n",
        "        test_accuracy = round((100 * test_correct / test_total), 2)\n",
        "        print(\"Test loss: {}, test accuracy: {}\". format(round((test_loss / len(labels)),2), test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njU_b0938thN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07d6777-9c4a-44b0-cef0-1e5a8b2d7180"
      },
      "source": [
        "d = 128 # size of word-embedding\n",
        "num_epochs = 30\n",
        "model = Baseline(d=128)\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_baseline.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: Training Loss- 65647.65 , Val Loss- 1418.86 , Training Acc- 64.27, Val Acc- 74.37\n",
            "epoch 1: Training Loss- 33663.40 , Val Loss- 1347.99 , Training Acc- 78.30, Val Acc- 77.82\n",
            "epoch 2: Training Loss- 28251.81 , Val Loss- 1158.29 , Training Acc- 82.68, Val Acc- 83.01\n",
            "epoch 3: Training Loss- 24638.87 , Val Loss- 1199.34 , Training Acc- 85.32, Val Acc- 83.14\n",
            "epoch 4: Training Loss- 21758.73 , Val Loss- 1244.83 , Training Acc- 87.06, Val Acc- 85.01\n",
            "epoch 5: Training Loss- 19489.57 , Val Loss- 1239.51 , Training Acc- 88.39, Val Acc- 85.99\n",
            "epoch 6: Training Loss- 19327.20 , Val Loss- 1296.61 , Training Acc- 88.58, Val Acc- 85.99\n",
            "epoch 7: Training Loss- 17280.85 , Val Loss- 1316.56 , Training Acc- 89.71, Val Acc- 86.80\n",
            "epoch 8: Training Loss- 16001.65 , Val Loss- 1494.07 , Training Acc- 90.39, Val Acc- 86.89\n",
            "epoch 9: Training Loss- 15093.05 , Val Loss- 1589.43 , Training Acc- 91.14, Val Acc- 87.31\n",
            "epoch 10: Training Loss- 14603.18 , Val Loss- 1632.44 , Training Acc- 91.39, Val Acc- 86.08\n",
            "epoch 11: Training Loss- 13766.97 , Val Loss- 1578.52 , Training Acc- 91.77, Val Acc- 87.87\n",
            "epoch 12: Training Loss- 13171.40 , Val Loss- 1862.06 , Training Acc- 92.08, Val Acc- 87.14\n",
            "epoch 13: Training Loss- 13560.01 , Val Loss- 1743.63 , Training Acc- 91.72, Val Acc- 86.72\n",
            "epoch 14: Training Loss- 13911.31 , Val Loss- 1898.86 , Training Acc- 91.23, Val Acc- 87.23\n",
            "epoch 15: Training Loss- 13706.48 , Val Loss- 1954.72 , Training Acc- 91.20, Val Acc- 87.65\n",
            "epoch 16: Training Loss- 13254.42 , Val Loss- 1962.11 , Training Acc- 91.33, Val Acc- 87.19\n",
            "epoch 17: Training Loss- 13439.23 , Val Loss- 1978.68 , Training Acc- 91.43, Val Acc- 87.23\n",
            "epoch 18: Training Loss- 12989.12 , Val Loss- 2193.57 , Training Acc- 91.64, Val Acc- 86.55\n",
            "epoch 19: Training Loss- 12915.06 , Val Loss- 2042.71 , Training Acc- 91.76, Val Acc- 87.31\n",
            "epoch 20: Training Loss- 12560.99 , Val Loss- 2089.98 , Training Acc- 91.87, Val Acc- 87.57\n",
            "epoch 21: Training Loss- 12390.72 , Val Loss- 2231.29 , Training Acc- 91.93, Val Acc- 87.23\n",
            "epoch 22: Training Loss- 12270.12 , Val Loss- 2294.07 , Training Acc- 91.99, Val Acc- 87.65\n",
            "epoch 23: Training Loss- 12356.31 , Val Loss- 2312.67 , Training Acc- 91.93, Val Acc- 86.89\n",
            "epoch 24: Training Loss- 12395.70 , Val Loss- 2359.56 , Training Acc- 91.92, Val Acc- 87.27\n",
            "epoch 25: Training Loss- 12386.24 , Val Loss- 2447.05 , Training Acc- 91.94, Val Acc- 86.63\n",
            "epoch 26: Training Loss- 12099.50 , Val Loss- 2616.45 , Training Acc- 92.09, Val Acc- 86.89\n",
            "epoch 27: Training Loss- 12478.77 , Val Loss- 2356.45 , Training Acc- 91.79, Val Acc- 87.10\n",
            "epoch 28: Training Loss- 12301.70 , Val Loss- 2395.78 , Training Acc- 91.59, Val Acc- 87.06\n",
            "epoch 29: Training Loss- 12274.63 , Val Loss- 2429.02 , Training Acc- 91.62, Val Acc- 87.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-4xTbPvKuKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0d65f3-5313-42c1-db0c-5babcde107bd"
      },
      "source": [
        "test_text = test_tsv_read['sentence']\n",
        "test_labels = list(test_tsv_read['label'])\n",
        "test_text = list(test_text.str.lower())\n",
        "test_tokens, test_token_ids = tokenization(test_text)\n",
        "test(model, test_token_ids, test_labels, 'best_baseline.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Test loss: 0.72, test accuracy: 78.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbqHYbKRuPh3"
      },
      "source": [
        "<font color='blue'>The model is trained for 30 epoch and the best model based on performance on the validation split is obtained at 12th epoch. The accuracy of the model is **78.21%** on the dev set.<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwer7ye-KuKb"
      },
      "source": [
        "**Problem 3.2** *(10 points)* Implement a recurrent neural network (without using PyTorch's RNN module) where the output of the linear layer not only depends on the current input but also the previous output. Report the model's accuracy on the dev data. Is it better or worse than the baseline? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_jxYAfvXIB"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 3.2}}$\n",
        "<font color='blue'> Training the model on 65000 samples of train set; validating using remaining samples of train set; testing it on the dev set.\n",
        "Here, the **`train function`** and **`test function`** defined in **solution 3.1** is used. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FQAQQ71KuKb"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of recurrent neural network using\n",
        "    `nn.Linear` class\n",
        "    3 types of layer connections:\n",
        "    - input to hidden layer\n",
        "    - hidden to hidden\n",
        "    - hidden to output\n",
        "    - hiddens to all \n",
        "    weights are shared across time \n",
        "    \"\"\"\n",
        "    def __init__(self, d):\n",
        "        super(RNN, self).__init__()\n",
        "        # Set the sizes of layers and more.\n",
        "        self.input_size = d # size of word_embeddings\n",
        "        self.hidden_size = d # size of hidden layers\n",
        "        self.output_size = 2 # size of output\n",
        "\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        self.x2h = nn.Linear(self.input_size, self.hidden_size)    # input to hidden \n",
        "        self.h2h = nn.Linear(self.hidden_size, self.hidden_size)    # hidden to  hidden\n",
        "        self.h2y = nn.Linear(self.hidden_size, self.output_size, bias=True)  # hidden to output\n",
        "\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        emb = self.embedding(input_tensor)\n",
        "        h = torch.zeros(1, self.hidden_size)\n",
        "        for i in range(emb.shape[1]):\n",
        "            h = torch.tanh(self.h2h(h) + self.x2h(emb[:,i,:]))   \n",
        "        out = self.h2y(h)\n",
        "        return out\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6jlTpd3XxIl",
        "outputId": "f6fed84f-45e4-44c6-fd45-7b0af7bc26b7"
      },
      "source": [
        "# d = 128 # size of word-embedding\n",
        "num_epochs = 20\n",
        "model = RNN(d=128)\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_rnn.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: Training Loss- 392037.07 , Val Loss- 10098.62 , Training Acc- 51.32, Val Acc- 54.45\n",
            "epoch 1: Training Loss- 388190.52 , Val Loss- 12706.09 , Training Acc- 52.00, Val Acc- 51.85\n",
            "epoch 2: Training Loss- 385291.59 , Val Loss- 11382.55 , Training Acc- 52.33, Val Acc- 51.81\n",
            "epoch 3: Training Loss- 385804.41 , Val Loss- 13494.90 , Training Acc- 52.23, Val Acc- 50.79\n",
            "epoch 4: Training Loss- 384812.21 , Val Loss- 11289.45 , Training Acc- 52.45, Val Acc- 52.66\n",
            "epoch 5: Training Loss- 381607.05 , Val Loss- 10052.96 , Training Acc- 52.79, Val Acc- 51.17\n",
            "epoch 6: Training Loss- 381293.32 , Val Loss- 12750.19 , Training Acc- 52.83, Val Acc- 52.70\n",
            "epoch 7: Training Loss- 379108.14 , Val Loss- 11628.76 , Training Acc- 53.17, Val Acc- 51.81\n",
            "epoch 8: Training Loss- 379794.24 , Val Loss- 11344.03 , Training Acc- 53.11, Val Acc- 52.75\n",
            "epoch 9: Training Loss- 378869.61 , Val Loss- 9530.38 , Training Acc- 53.15, Val Acc- 50.96\n",
            "epoch 10: Training Loss- 379121.06 , Val Loss- 10143.09 , Training Acc- 53.10, Val Acc- 52.62\n",
            "epoch 11: Training Loss- 379206.65 , Val Loss- 10588.39 , Training Acc- 53.11, Val Acc- 53.34\n",
            "epoch 12: Training Loss- 378552.06 , Val Loss- 9260.58 , Training Acc- 53.12, Val Acc- 51.55\n",
            "epoch 13: Training Loss- 377697.03 , Val Loss- 10608.54 , Training Acc- 53.29, Val Acc- 54.83\n",
            "epoch 14: Training Loss- 377217.44 , Val Loss- 10059.50 , Training Acc- 53.28, Val Acc- 52.15\n",
            "epoch 15: Training Loss- 379263.91 , Val Loss- 10236.70 , Training Acc- 53.10, Val Acc- 54.19\n",
            "epoch 16: Training Loss- 377317.54 , Val Loss- 11249.61 , Training Acc- 53.34, Val Acc- 52.66\n",
            "epoch 17: Training Loss- 378415.00 , Val Loss- 8149.68 , Training Acc- 53.26, Val Acc- 52.92\n",
            "epoch 18: Training Loss- 376876.37 , Val Loss- 9624.87 , Training Acc- 53.41, Val Acc- 51.30\n",
            "epoch 19: Training Loss- 376167.44 , Val Loss- 10560.02 , Training Acc- 53.44, Val Acc- 55.81\n",
            "Best accuracy at epoch: 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr2tefDuUV4N",
        "outputId": "8fdd9ecb-7c42-443f-8ad5-0be72fd0b164"
      },
      "source": [
        "test(model, test_token_ids, test_labels, 'best_rnn.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 4.95, test accuracy: 51.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqsxJBFvbgZ"
      },
      "source": [
        "<font color='blue'>The model is trained for 20 epoch and the best model based on performance on the validation split is obtained at 20th epoch. The accuracy of the model is **51.72%** on the dev set.<font>\n",
        "\n",
        "<font color='blue'> Based on the accuracy of RNN and baseline model on the dev set, we can clearly say that the **RNN model is perfoming worse than the baseline model**. As the training and validation accuracy is also around 55%, it implies that model is not learning properly. **This maybe be primarily because the gradients might be vanishing or exploding (also known as vanishing/exploding gradient problem) and hence the model is not able to learn properly.**<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTFrTLXQKuKb"
      },
      "source": [
        "\n",
        "**Problem 3.3 (bonus)** *(10 points)* Show that the cross entropy computed above is equivalent to the negative log likelihood of the probability distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmn5OTNti0-P"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 3.3}}$\n",
        "**Mathematically**\n",
        "\n",
        "<font color='blue'>**Cross-entropy is a measure of the difference between two probability distributions**. Cross entropy loss measures the performance of a classification model whose output is a probability value between 0 and 1. It increases as the predicted probability diverges from the actual label. **Cross entropy loss** is mathematically defined as:\n",
        "$$H(p,q) = - \\sum_{i} P_{i} \\log q_{i}$$,\n",
        "where $q_{i}$ is the estimated probability of outcome $i$ and $p_{i}$ is the empirical probability of outcome $i$ in the training data. <font>\n",
        "\n",
        "<font color='blue'> The **likelihood of training set** is given by:\n",
        "$$\\text{likelihood} = \\prod_{i} q_{i}^{Np_{i}} $$\n",
        "where $q_{i}$ is the estimated probability of outcome $i$, $p_{i}$ is the empirical probability of outcome $i$ in the training data and N is the number of independent samples in the training set.\n",
        "\n",
        "**On taking logarithm of likelihood followed by dividing it by N**, we get\n",
        "$$\\frac{1}{N} \\log \\prod_{i} q_{i}^{Np_{i}}  = \\sum_{i} P_{i} \\log q_{i} = - H(p,q) $$\n",
        "</font>\n",
        "<font color='blue'> \n",
        "Hence, proved that mathematically the cross-entropy is equivalent to the negative log likelihood of the probability distribution.<font>\n",
        "\n",
        "**Based on experiments**\n",
        "\n",
        "<font color='blue'>Additionally, I performed a small experiment in the cell below to verify this. I used the baseline model and during inference time checked the value of cross entropy loss and nll loss. Based on the loss values obtained in the cell below, it is proved that the cross entropy computed above is equivalent to the negative log likelihood of the probability distribution. <font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxe6YpSm4YF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1ae29d-d957-4f72-fbb4-008e5f34aea3"
      },
      "source": [
        "# Test sample\n",
        "input_tensor = torch.LongTensor([token_ids[10]])\n",
        "label = torch.LongTensor([labels[10]])\n",
        "\n",
        "#Loading baseline model\n",
        "model = Baseline(128)\n",
        "best_file = os.path.join(result_path, \"best_baseline.pt\")\n",
        "model.load_state_dict(torch.load(best_file))\n",
        "model.eval()\n",
        "logits = model(input_tensor)\n",
        "\n",
        "# Cross entropy loss\n",
        "ce = nn.CrossEntropyLoss()\n",
        "loss1 = ce(logits, label)\n",
        "m = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "# NLL loss\n",
        "nll_loss = nn.NLLLoss()\n",
        "loss2 = nll_loss(m(logits), label)\n",
        "print(\"Cross entropy loss is \", loss1.item())\n",
        "print(\"NLL loss is \", loss2.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross entropy loss is  4.339123915997334e-05\n",
            "NLL loss is  4.339123915997334e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRFslV8mCpTo"
      },
      "source": [
        "\n",
        "**Problem 3.4 (bonus)** *(10 points)* Why is it numerically unstable if you compute log on top of softmax?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OqQX52zsehR"
      },
      "source": [
        "<font color='blue'> Computing log on top of softmax is numerically unstable as it may lead to **underflow** in case of, **$log(0)$**, which is undefined. The logarithm function is not defined for zero, so log probabilities can only represent non-zero probabilities. \n",
        "\n",
        "<font color='blue'> ***In the cell below, we do a simple experiment to prove that computing log on top of softmax is numerically unstable, particularly numerical underflow.***\n",
        "In this example, we have an input vector containing one value significantly larger than the rest of values. <font>\n",
        "<font color='blue'>\n",
        "$$x = [10, 2, 10000, 4]$$\n",
        "\n",
        "<font color='blue'>\n",
        "Computing softmax on this vector generates: \n",
        "\n",
        "<font color='blue'>\n",
        "$$ softmax(x) = [0., 0., 1., 0.]$$\n",
        "\n",
        "<font color='blue'>\n",
        "Since $x$ contains a significantly larger number at index $2$ and all the other values are very small, softmax of this vector generates probability $1$ for value at index $1$ and probability $0$ for rest of the values.\n",
        "\n",
        "<font color='blue'>\n",
        "Computing log of softmax(x) generates: \n",
        "\n",
        "<font color='blue'>\n",
        "$$\\log(softmax(x)) = [-inf, -inf,   0., -inf]$$\n",
        "\n",
        "<font color='blue'>\n",
        "Since log(0) is not defined, we get the error \"*RuntimeWarning: divide by zero encountered in log*\" and this is a classic example of numerical instabilty, particularly numerical underflow.\n",
        "\n",
        "<font color='blue'>Hence, **computing log on top of softmax is numerically unstable.**<font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeroxgDPOJxM",
        "outputId": "c1487aec-74e9-4b9d-b6c8-197fc0941560"
      },
      "source": [
        "import numpy as np\n",
        "def softmax(x):\n",
        "    max_x = np.max(x)\n",
        "    exp_x = np.exp(x - max_x)\n",
        "    sum_exp_x = np.sum(exp_x)\n",
        "    sm_x = exp_x/sum_exp_x\n",
        "    return sm_x\n",
        "    \n",
        "x = np.array([10, 2, 10000, 4])\n",
        "softmax(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Cuwp89OJ-R",
        "outputId": "4e858e10-cced-4132-c435-8ec835c23fdf"
      },
      "source": [
        "np.log(softmax(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-inf, -inf,   0., -inf])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJtE3_7jOwg_"
      },
      "source": [
        "<font color='blue'>This is an example where computing log on top of softmax leads to numerical instability, in particular, numerical underflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBLmpKJRAd1h"
      },
      "source": [
        "## 4. Text Classification with LSTM and Dropout\n",
        "\n",
        "Now it is time to drastically improve your baselines! Replace your RNN module with an LSTM module. See Lecture slides 04 and 05 for the formal definition of LSTMs. \n",
        "\n",
        "You will also use Dropout, which randomly makes each dimension zero with the probability of `p` and scale it by `1/(1-p)` if it is not zero during training. Put it either at the input or the output of the LSTM to prevent it from overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8H0F-csCCk0",
        "outputId": "37826658-1f91-4b45-fa60-b1c332c23cc8"
      },
      "source": [
        "a = torch.FloatTensor([0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "dropout = nn.Dropout(0.5) # p=0.5\n",
        "print(dropout(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.6000, 0.0000, 0.0000, 0.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6boSxKjC4Mw"
      },
      "source": [
        "**Problem 4.1** *(20 points)* Use LSTM instead of vanilla RNN to improve your model. Report the accuracy on the dev data.\n",
        "\n",
        "**Problem 4.2** *(10 points)* Use Dropout on LSTM (either at input or output). Report the accuracy on the dev data and briefly describe how it differs from 4.1.\n",
        "\n",
        "**Problem 4.3 (bonus)** *(10 points)* Consider implementing bidirectional LSTM and two layers of LSTM to further improve your model. Report your accuracy on dev data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjTdcAwuPBPH"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 4.1}}$\n",
        "<font color='blue'> Training the model on 65000 samples of train set; validating using remaining samples of train set; testing it on the dev set.\n",
        "Here, the **`train function`** and **`test function`** defined in **solution 3.1** is used. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htbF-qctA6MP"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, d, dropout = None):\n",
        "        \"\"\"\n",
        "        Implementation of recurrent neural network using\n",
        "        `nn.Linear` and `nn.Parameter`class\n",
        "        \"\"\"\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_size = d\n",
        "        self.hidden_size = d\n",
        "        self.output_size = 2\n",
        "        self.drop = dropout\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        # i_t, c_t, f_t, o_t\n",
        "        self.W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.output_size, bias=True) \n",
        "\n",
        "        self.init_weights()\n",
        "                \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
        "        # print(input_tensor.shape)\n",
        "        emb = self.embedding(input_tensor)\n",
        "        batch_size = emb.shape[0]\n",
        "\n",
        "        h_t, c_t = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "          \n",
        "        ds = self.hidden_size\n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.W + h_t @ self.U + self.b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t = f_t * c_t + i_t * g_t\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        if (self.drop != None):\n",
        "          h_t = self.dropout(h_t)\n",
        "          out = self.linear(h_t)\n",
        "        else:\n",
        "          out = self.linear(h_t)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFj-PJoBDAl0"
      },
      "source": [
        "# num_epochs = 14\n",
        "# model = LSTM(d=128)\n",
        "# train_loss, train_acc, val_loss, val_acc = train(model, token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_lstm.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlCjvs7CPOk6",
        "outputId": "a3f7fdbe-120b-4911-b14e-b2405f3d8146"
      },
      "source": [
        "test('LSTM', test_token_ids, test_labels, 'best_lstm.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.02, test accuracy: 83.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuOAbfhvRmEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2713d2-5ec0-4afc-cf59-3713769a5afa"
      },
      "source": [
        "d = 128 # size of word-embedding\n",
        "num_epochs = 14\n",
        "model = LSTM(d=128)\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_lstm_v2.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: Training Loss- 29851.19 , Val Loss- 662.57 , Training Acc- 76.46, Val Acc- 88.72\n",
            "epoch 1: Training Loss- 13292.34 , Val Loss- 550.47 , Training Acc- 92.31, Val Acc- 91.36\n",
            "epoch 2: Training Loss- 8900.31 , Val Loss- 612.81 , Training Acc- 94.94, Val Acc- 91.40\n",
            "epoch 3: Training Loss- 6605.37 , Val Loss- 720.49 , Training Acc- 96.12, Val Acc- 91.49\n",
            "epoch 4: Training Loss- 5250.48 , Val Loss- 750.51 , Training Acc- 96.91, Val Acc- 91.78\n",
            "epoch 5: Training Loss- 4233.30 , Val Loss- 799.96 , Training Acc- 97.44, Val Acc- 91.06\n",
            "epoch 6: Training Loss- 3518.11 , Val Loss- 978.44 , Training Acc- 97.92, Val Acc- 91.27\n",
            "epoch 7: Training Loss- 3123.30 , Val Loss- 1093.42 , Training Acc- 98.19, Val Acc- 91.02\n",
            "epoch 8: Training Loss- 2797.79 , Val Loss- 1197.00 , Training Acc- 98.38, Val Acc- 91.53\n",
            "epoch 9: Training Loss- 2601.87 , Val Loss- 1046.80 , Training Acc- 98.52, Val Acc- 91.70\n",
            "epoch 10: Training Loss- 2259.63 , Val Loss- 1211.96 , Training Acc- 98.72, Val Acc- 91.83\n",
            "epoch 11: Training Loss- 2163.82 , Val Loss- 1302.87 , Training Acc- 98.78, Val Acc- 91.49\n",
            "epoch 12: Training Loss- 2203.60 , Val Loss- 1307.54 , Training Acc- 98.73, Val Acc- 91.61\n",
            "epoch 13: Training Loss- 1876.64 , Val Loss- 1326.44 , Training Acc- 98.93, Val Acc- 92.17\n",
            "Best accuracy at epoch: 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UAqBsMLRmRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb953ec4-5ce4-4e6f-958f-71479dbeae32"
      },
      "source": [
        "model = LSTM(d=128)\n",
        "test(model, test_token_ids, test_labels, 'best_lstm_v2.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.01, test accuracy: 82.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0y_wDarQvUz"
      },
      "source": [
        "<font color='blue'>Now, I used the LSTM model instead of vanilla RNN. The model is trained two times for 20 and 14 epochs respectively. The best model based on performance on the validation split is obtained at 11th and 14th epoch respectively. The accuracy of the models are **83.14%** and **82.34%** respectively on the dev set.<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-unuX3itMbf"
      },
      "source": [
        "Problem 4.2 (10 points) Use Dropout on LSTM (either at input or output). Report the accuracy on the dev data and briefly describe how it differs from 4.1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG7hHrZnoBWI"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 4.2}}$\n",
        "<font color='blue'> Training the model on 65000 samples of train set; validating using remaining samples of train set; testing it on the dev set.\n",
        "Here, the **`train function`** and **`test function`** defined in **solution 3.1** is used. I used dropout(p=0.5) and dropout(p=0.25) at the output layer. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4l7Qir5n7XL",
        "outputId": "f3bd97e2-9928-4cb0-808b-8564585932d4"
      },
      "source": [
        "d = 128 # size of word-embedding\n",
        "num_epochs = 12\n",
        "model = LSTM(d, 'dropout')\n",
        "train_loss, train_acc, val_loss, val_acc = train('LSTM_with_dropout', token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_lstm_with_dropout.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: Training Loss- 31048.76 , Val Loss- 665.26 , Training Acc- 75.44, Val Acc- 88.34\n",
            "epoch 1: Training Loss- 14554.30 , Val Loss- 552.70 , Training Acc- 91.52, Val Acc- 90.51\n",
            "epoch 2: Training Loss- 9957.78 , Val Loss- 577.75 , Training Acc- 94.41, Val Acc- 91.49\n",
            "epoch 3: Training Loss- 7421.37 , Val Loss- 609.56 , Training Acc- 95.65, Val Acc- 92.08\n",
            "epoch 4: Training Loss- 5983.45 , Val Loss- 702.58 , Training Acc- 96.38, Val Acc- 91.74\n",
            "epoch 5: Training Loss- 5030.75 , Val Loss- 841.36 , Training Acc- 96.88, Val Acc- 91.70\n",
            "epoch 6: Training Loss- 4340.32 , Val Loss- 861.91 , Training Acc- 97.27, Val Acc- 91.49\n",
            "epoch 7: Training Loss- 3877.79 , Val Loss- 975.23 , Training Acc- 97.60, Val Acc- 92.08\n",
            "epoch 8: Training Loss- 3506.09 , Val Loss- 946.87 , Training Acc- 97.81, Val Acc- 92.04\n",
            "epoch 9: Training Loss- 3325.59 , Val Loss- 893.63 , Training Acc- 97.95, Val Acc- 92.04\n",
            "epoch 10: Training Loss- 3219.58 , Val Loss- 1005.38 , Training Acc- 98.03, Val Acc- 92.21\n",
            "epoch 11: Training Loss- 2869.30 , Val Loss- 949.53 , Training Acc- 98.23, Val Acc- 92.42\n",
            "Best accuracy at epoch: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57tqFd5ovAnW",
        "outputId": "e9b75993-7631-4199-f99d-0698451093b2"
      },
      "source": [
        "test_text = test_tsv_read['sentence']\n",
        "test_labels = list(test_tsv_read['label'])\n",
        "test_text = list(test_text.str.lower())\n",
        "test_tokens, test_token_ids = tokenization(test_text)\n",
        "d = 128\n",
        "model = LSTM(d, 'dropout')\n",
        "test(model, test_token_ids, test_labels, 'best_lstm_with_dropout.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.99, test accuracy: 82.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLlVxAaJApL_"
      },
      "source": [
        "<font color='blue'> I added **dropout(p=0.5) at the output of the LSTM** to prevent it from overfitting and trained the model for 20 epochs. The best model based on performance on the validation split is obtained at 12th epoch. The accuracy of the model is **82.11%** on the dev set. \n",
        "It can be observed that **LSTM model(solution 4.1) outperforms LSTM model with dropout (at the output layer)**. Hence, adding dropout(p=0.5) at the output layer does not improve the classification performance. This may be because the dimension of the output of the LSTM is 128 and dropping half of them may result in loosing some important information. Dropout may help in preventing overfitting in case the output dimension is very large (1024 or 2048). <font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-QuJJ4UG7JF",
        "outputId": "2d3c7dd0-1614-4312-f973-eb1004e6b8ab"
      },
      "source": [
        "d = 128 # size of word-embedding\n",
        "num_epochs = 12\n",
        "model = LSTM(d, 'dropout')\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_lstm_with_dropout_v2.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: Training Loss- 30602.65 , Val Loss- 691.71 , Training Acc- 75.65, Val Acc- 88.04\n",
            "epoch 1: Training Loss- 14054.04 , Val Loss- 586.01 , Training Acc- 91.77, Val Acc- 91.19\n",
            "epoch 2: Training Loss- 9542.08 , Val Loss- 557.85 , Training Acc- 94.61, Val Acc- 91.87\n",
            "epoch 3: Training Loss- 7170.22 , Val Loss- 628.99 , Training Acc- 95.79, Val Acc- 91.66\n",
            "epoch 4: Training Loss- 5456.86 , Val Loss- 758.17 , Training Acc- 96.67, Val Acc- 92.00\n",
            "epoch 5: Training Loss- 4532.95 , Val Loss- 793.72 , Training Acc- 97.24, Val Acc- 92.00\n",
            "epoch 6: Training Loss- 3864.70 , Val Loss- 932.18 , Training Acc- 97.67, Val Acc- 92.08\n",
            "epoch 7: Training Loss- 3557.85 , Val Loss- 932.38 , Training Acc- 97.85, Val Acc- 92.51\n",
            "epoch 8: Training Loss- 3345.23 , Val Loss- 988.03 , Training Acc- 98.03, Val Acc- 92.25\n",
            "epoch 9: Training Loss- 2848.40 , Val Loss- 1103.57 , Training Acc- 98.29, Val Acc- 91.53\n",
            "epoch 10: Training Loss- 2436.67 , Val Loss- 1237.35 , Training Acc- 98.54, Val Acc- 92.46\n",
            "epoch 11: Training Loss- 2361.22 , Val Loss- 1103.11 , Training Acc- 98.64, Val Acc- 92.81\n",
            "Best accuracy at epoch: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rL7MZr0rrp8",
        "outputId": "56b4636e-5fd9-46fe-dee4-9c04b180f6da"
      },
      "source": [
        "d = 128\n",
        "model = LSTM(d, 'dropout')\n",
        "test(model, test_token_ids, test_labels, 'best_lstm_with_dropout_v2.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.01, test accuracy: 83.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5hGSK4QMJha"
      },
      "source": [
        "<font color='blue'> I added **dropout(p=0.25) at the output of the LSTM** to prevent it from overfitting and trained the model for 20 epochs. The best model based on performance on the validation split is obtained at 12th epoch. The accuracy of the model is **83.78%** on the dev set. \n",
        "It can be observed that **LSTM model with dropout (at the output layer) outperforms the LSTM model(solution 4.1)**. Hence, adding dropout(p=0.25) at the output layer improves the classification performance.\n",
        "\n",
        "<font color='blue'> In summary, adding dropout(p=0.25) improves the classification performance whereas adding dropout(p=0.5) degrades the classification performance. This may be because the dimension of the output of the LSTM is 128 and dropping half of them may result in loosing some important information. On the contrary, dropout(p=0.25) drops less nodes and most of the important information is not dropped and helps in improving the test performance. Dropout(p=0.5) may help in preventing overfitting in case the output dimension is very large (1024 or 2048). <font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPKhF5vzCYgN"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 4.3.1}}$\n",
        "<font color='blue'> Implementing **bidirectional LSTM** to further improve the model. \n",
        " Training the model on 65000 samples of train set; validating using remaining samples of train set; testing it on the dev set.\n",
        "Here, the **`train function`** and **`test function`** defined in **solution 3.1** is used. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmqvcYVD2AQv"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, d, dropout = None):\n",
        "        \"\"\"\n",
        "        Implementation of recurrent neural network using\n",
        "        `nn.Linear` and `nn.Parameter`class\n",
        "        \"\"\"\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.input_size = d\n",
        "        self.hidden_size = d\n",
        "        self.output_size = 2\n",
        "\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        # i_t, c_t, f_t, o_t\n",
        "        self.W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.Wb = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.Ub = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.bb = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.linear = nn.Linear(self.hidden_size*2, self.output_size, bias=True) \n",
        "\n",
        "        self.init_weights()\n",
        "                \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
        "        # print(input_tensor.shape)\n",
        "        emb = self.embedding(input_tensor)\n",
        "        batch_size = emb.shape[0]\n",
        "\n",
        "        forward = []\n",
        "        backward = []\n",
        "        h_t_for, c_t_for = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "        h_t_back, c_t_back = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "          \n",
        "        ds = self.hidden_size\n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.W + h_t_for @ self.U + self.b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t_for = f_t * c_t_for + i_t * g_t\n",
        "            h_t_for = o_t * torch.tanh(c_t_for)\n",
        "            forward.append(h_t_for)\n",
        "\n",
        "        for t in reversed(range(emb.shape[1])):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.Wb + h_t_back @ self.Ub + self.bb\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t_back = f_t * c_t_back + i_t * g_t\n",
        "            h_t_back = o_t * torch.tanh(c_t_back)\n",
        "            backward.append(h_t_back)\n",
        "\n",
        "        h_final= torch.cat((h_t_for, h_t_back), 1)\n",
        "        out = self.linear(h_final)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36rM7fQn6zmN",
        "outputId": "bcd643be-118c-4eea-8231-90f66df9e120"
      },
      "source": [
        "d = 128 # size of word-embedding\n",
        "num_epochs = 12\n",
        "model = BiLSTM(d)\n",
        "train_loss, train_acc, val_loss, val_acc = train(model, token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_bilstm.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: Training Loss- 28008.84 , Val Loss- 630.29 , Training Acc- 78.60, Val Acc- 89.14\n",
            "epoch 1: Training Loss- 12509.46 , Val Loss- 578.43 , Training Acc- 92.79, Val Acc- 91.61\n",
            "epoch 2: Training Loss- 8051.79 , Val Loss- 597.64 , Training Acc- 95.50, Val Acc- 92.00\n",
            "epoch 3: Training Loss- 5674.09 , Val Loss- 676.43 , Training Acc- 96.79, Val Acc- 92.29\n",
            "epoch 4: Training Loss- 4230.75 , Val Loss- 750.23 , Training Acc- 97.57, Val Acc- 92.29\n",
            "epoch 5: Training Loss- 3436.98 , Val Loss- 899.44 , Training Acc- 98.05, Val Acc- 92.08\n",
            "epoch 6: Training Loss- 2777.25 , Val Loss- 965.44 , Training Acc- 98.44, Val Acc- 92.17\n",
            "epoch 7: Training Loss- 2392.08 , Val Loss- 965.91 , Training Acc- 98.67, Val Acc- 92.42\n",
            "epoch 8: Training Loss- 2051.31 , Val Loss- 1072.55 , Training Acc- 98.95, Val Acc- 92.34\n",
            "epoch 9: Training Loss- 1918.34 , Val Loss- 1054.57 , Training Acc- 98.98, Val Acc- 92.38\n",
            "epoch 10: Training Loss- 1572.50 , Val Loss- 1117.17 , Training Acc- 99.15, Val Acc- 92.64\n",
            "epoch 11: Training Loss- 1500.22 , Val Loss- 1087.62 , Training Acc- 99.24, Val Acc- 93.02\n",
            "Best accuracy at epoch: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH6VK1vg6sJe",
        "outputId": "4a1babad-6870-4748-ecea-eaa0a230d4c3"
      },
      "source": [
        "test_text = test_tsv_read['sentence']\n",
        "test_labels = list(test_tsv_read['label'])\n",
        "test_text = list(test_text.str.lower())\n",
        "test_tokens, test_token_ids = tokenization(test_text)\n",
        "d = 128\n",
        "model = BiLSTM(d)\n",
        "test(model, test_token_ids, test_labels, 'best_bilstm.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.96, test accuracy: 86.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktIbmJvRWLNL"
      },
      "source": [
        "<font color='blue'>The model is trained for 12 epochs and the best model based on performance on the validation split is obtained at 12th epoch. The accuracy of the model is **86.32%** on the dev set. This model outperforms the LSTM model(solution 4.1). This model outperforms all the models trained in solution 3 and solution 4(namely baseline model, vanilla RNN, LSTM, LSTM with dropout).<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxrFN9URVynR"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 4.3.2}}$\n",
        "<font color='blue'> Implementing **bidirectional LSTM and two layers of LSTM** to further improve the model. \n",
        " Training the model on 65000 samples of train set; validating using remaining samples of train set; testing it on the dev set. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwcEmsL4UIz2"
      },
      "source": [
        "class BiLSTMv2(nn.Module):\n",
        "    def __init__(self, d, dropout = None):\n",
        "        \"\"\"\n",
        "        Implementation of recurrent neural network using\n",
        "        `nn.Linear` and `nn.Parameter`class\n",
        "        \"\"\"\n",
        "        super(BiLSTMv2, self).__init__()\n",
        "        self.input_size = d\n",
        "        self.hidden_size = d\n",
        "        self.output_size = 2\n",
        "        self.hidden_size1 = 2*d\n",
        "        \n",
        "        #BiLSTM\n",
        "        self.embedding = nn.Embedding(len(vocab), self.input_size)\n",
        "        # i_t, c_t, f_t, o_t\n",
        "        self.W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.Wb = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.Ub = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.bb = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        # LSTM1\n",
        "        self.W1 = nn.Parameter(torch.Tensor(self.input_size*2, self.hidden_size1 * 4))\n",
        "        self.U1 = nn.Parameter(torch.Tensor(self.hidden_size1, self.hidden_size1 * 4))\n",
        "        self.b1 = nn.Parameter(torch.Tensor(self.hidden_size1 * 4))\n",
        "        # LSTM2\n",
        "        self.W2 = nn.Parameter(torch.Tensor(self.input_size*2, self.hidden_size1 * 4))\n",
        "        self.U2 = nn.Parameter(torch.Tensor(self.hidden_size1, self.hidden_size1 * 4))\n",
        "        self.b2 = nn.Parameter(torch.Tensor(self.hidden_size1 * 4))\n",
        "\n",
        "\n",
        "        self.linear = nn.Linear(self.hidden_size1, self.output_size, bias=True) \n",
        "\n",
        "        self.init_weights()\n",
        "                \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
        "        # print(input_tensor.shape)\n",
        "        emb = self.embedding(input_tensor)\n",
        "        batch_size = emb.shape[0]\n",
        "\n",
        "        forward = []\n",
        "        backward = []\n",
        "\n",
        "        #BiLSTM\n",
        "        h_t_for, c_t_for = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "        h_t_back, c_t_back = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "        #LSTM1\n",
        "        h_t_1, c_t_1 = (torch.zeros(batch_size, self.hidden_size1).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size1).to(emb.device))\n",
        "        #LSTM2\n",
        "        h_t_2, c_t_2 = (torch.zeros(batch_size, self.hidden_size1).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size1).to(emb.device))\n",
        "        \n",
        "        #BiLSTM\n",
        "        ds = self.hidden_size\n",
        "        ds1 = self.hidden_size1\n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.W + h_t_for @ self.U + self.b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t_for = f_t * c_t_for + i_t * g_t\n",
        "            h_t_for = o_t * torch.tanh(c_t_for)\n",
        "            forward.append(h_t_for)\n",
        "\n",
        "        for t in reversed(range(emb.shape[1])):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.Wb + h_t_back @ self.Ub + self.bb\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t_back = f_t * c_t_back + i_t * g_t\n",
        "            h_t_back = o_t * torch.tanh(c_t_back)\n",
        "            backward.append(h_t_back)\n",
        "\n",
        "        #LSTM1\n",
        "        h_lstm1 = []\n",
        "        for fwd, bwd in zip(forward, backward):\n",
        "            # print(fwd.shape, bwd.shape)\n",
        "            input_tensor = torch.cat((fwd, bwd), 1)\n",
        "            gate = input_tensor @ self.W1 + h_t_1 @ self.U1 + self.b1\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds1]), \n",
        "                torch.sigmoid(gate[:, ds1:ds1*2]),  \n",
        "                torch.tanh(gate[:, ds1*2:ds1*3]),\n",
        "                torch.sigmoid(gate[:, ds1*3:]), \n",
        "            )\n",
        "            c_t_1 = f_t * c_t_1 + i_t * g_t\n",
        "            h_t_1 = o_t * torch.tanh(c_t_1)\n",
        "            h_lstm1.append(h_t_1)\n",
        "\n",
        "        #LSTM2\n",
        "        h_lstm2 = []\n",
        "        for input_tensor in h_lstm1:\n",
        "            gate = input_tensor @ self.W2 + h_t_2 @ self.U2 + self.b2\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds1]), \n",
        "                torch.sigmoid(gate[:, ds1:ds1*2]),  \n",
        "                torch.tanh(gate[:, ds1*2:ds1*3]),\n",
        "                torch.sigmoid(gate[:, ds1*3:]), \n",
        "            )\n",
        "            c_t_2 = f_t * c_t_2 + i_t * g_t\n",
        "            h_t_2 = o_t * torch.tanh(c_t_2)\n",
        "            h_lstm2.append(h_t_2)\n",
        "\n",
        "        out = self.linear(h_t_2)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RefgHrjGUJCV"
      },
      "source": [
        "# result_path = '/home/radhika/radhika_77/data/nlp/models/'\n",
        "result_path = '/content/drive/MyDrive/nlp/'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "softmax = nn.Softmax(1) \n",
        "\n",
        "def train(model, data, labels, val_data, val_labels, num_epochs = 12, file = None):    \n",
        "    if (file != None):\n",
        "      best_file = os.path.join(result_path, file)\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "    best_acc = 0\n",
        "    best_acc_epoch = 0\n",
        "    \n",
        "    train_loss=[]\n",
        "    train_acc=[]\n",
        "    val_loss = []\n",
        "    val_acc=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      epoch_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      epoch_acc = 0\n",
        "      for i in range(len(labels)):\n",
        "          input_tensor = torch.LongTensor([data[i]])\n",
        "          label = torch.LongTensor([labels[i]])\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          logits = model(input_tensor)\n",
        "          loss = criterion(logits, label)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          _, predicted = torch.max(logits.data, 1)\n",
        "          total += label.size(0)\n",
        "          correct += (predicted == label).sum().item()\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "      epoch_acc = (100 * correct / total)\n",
        "      train_loss.append(round((epoch_loss / len(labels)), 2))\n",
        "      train_acc.append(round((epoch_acc),2))\n",
        "\n",
        "      with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_epoch_loss = 0\n",
        "            val_total = 0\n",
        "            val_correct = 0\n",
        "            epoch_val_acc = 0\n",
        "            for i in range(len(val_labels)):\n",
        "                input_tensor, label = val_data[i], val_labels[i]\n",
        "                input_tensor = torch.LongTensor([input_tensor])\n",
        "                label = torch.LongTensor([label])\n",
        "                logits = model(input_tensor)\n",
        "                loss = criterion(logits, label)\n",
        "                _, predicted = torch.max(logits.data, 1)\n",
        "                val_total += label.size(0)\n",
        "                val_correct += (predicted == label).sum().item()\n",
        "                val_epoch_loss += loss.item()\n",
        "\n",
        "            val_loss.append(round((val_epoch_loss / len(val_labels)),2))\n",
        "            epoch_val_acc = (100 * val_correct / val_total)\n",
        "            val_acc.append(round((epoch_val_acc),2))\n",
        "      # print(\"epoch {}: Training Loss- {:.2f} , Val Loss- {:.2f} , Training Acc- {:.2f}, Val Acc- {:.2f}\".format(epoch, epoch_loss, val_epoch_loss, epoch_acc, epoch_val_acc))\n",
        "      if (epoch_val_acc >= best_acc):\n",
        "            best_acc = epoch_val_acc\n",
        "            best_acc_epoch = epoch\n",
        "            if (file!=None):\n",
        "              torch.save(model.state_dict(), best_file)         \n",
        "      if (epoch == num_epochs - 1):\n",
        "        print(\"Best accuracy at epoch: {}\".format(best_acc_epoch))\n",
        "    return model, train_loss, train_acc, val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMgthgjWUJOU",
        "outputId": "638842af-26d9-4efb-9837-e27cabf1ed54"
      },
      "source": [
        "d = 128 # size of word-embedding\n",
        "num_epochs = 11\n",
        "model = BiLSTMv2(d)\n",
        "model, train_loss, train_acc, val_loss, val_acc = train(model, token_ids, labels, val_token_ids, val_labels, num_epochs, 'best_bilstm_v2.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0: Training Loss- 39540.20 , Val Loss- 877.73 , Training Acc- 63.37, Val Acc- 83.91\n",
            "epoch 1: Training Loss- 18006.32 , Val Loss- 605.49 , Training Acc- 89.02, Val Acc- 90.38\n",
            "epoch 2: Training Loss- 10992.66 , Val Loss- 592.08 , Training Acc- 93.92, Val Acc- 91.74\n",
            "epoch 3: Training Loss- 7898.49 , Val Loss- 636.27 , Training Acc- 95.76, Val Acc- 92.08\n",
            "epoch 4: Training Loss- 6086.68 , Val Loss- 659.23 , Training Acc- 96.66, Val Acc- 91.91\n",
            "epoch 5: Training Loss- 4977.78 , Val Loss- 699.48 , Training Acc- 97.23, Val Acc- 92.55\n",
            "epoch 6: Training Loss- 3962.54 , Val Loss- 800.84 , Training Acc- 97.76, Val Acc- 92.12\n",
            "epoch 7: Training Loss- 3289.22 , Val Loss- 846.90 , Training Acc- 98.13, Val Acc- 92.38\n",
            "epoch 8: Training Loss- 3137.43 , Val Loss- 715.26 , Training Acc- 98.20, Val Acc- 92.76\n",
            "epoch 9: Training Loss- 2620.80 , Val Loss- 889.52 , Training Acc- 98.50, Val Acc- 92.64\n",
            "epoch 10: Training Loss- 2266.90 , Val Loss- 871.81 , Training Acc- 98.74, Val Acc- 92.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymqgXnhPUJbp",
        "outputId": "27999c15-50db-4598-e186-120fa2f50f6d"
      },
      "source": [
        "test_text = test_tsv_read['sentence']\n",
        "test_labels = list(test_tsv_read['label'])\n",
        "test_text = list(test_text.str.lower())\n",
        "test_tokens, test_token_ids = tokenization(test_text)\n",
        "test(model, test_token_ids, test_labels, 'best_bilstm_v2.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.97, test accuracy: 87.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNa54fzIX8qZ"
      },
      "source": [
        "<font color='blue'>The model is trained for 11 epochs. The accuracy of the model is 87.43% on the dev set. This model outperforms all the models trained in solution 3 and solution 4(namely baseline model, vanilla RNN, LSTM, LSTM with dropout).<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855DrT78DXps"
      },
      "source": [
        "## 5. Pretrained Word Vectors\n",
        "The last step is to use pretrained vocabulary and word vectors. The prebuilt vocabulary will replace the vocabulary you built with SST-2 training data, and the word vectors will replace the embedding vectors. You will observe the power of leveraging self-supservised pretrained models.\n",
        "\n",
        "**Problem 5.1** *(10 points)* Go to https://nlp.stanford.edu/projects/glove/ and download `glove.6B.zip`. Use these pretrained word vectors to further improve your model from 4.2. Report the model's accuracy on the dev data.\n",
        "\n",
        "**Problem 5.2 (bonus)** *(10 points)* You can go one step further by using word vectors obtained from pretrained language models. Can you import the word embeddings from `bert-base-uncased` model (via Hugging Face's `transformers`: https://huggingface.co/transformers/pretrained_models.html) into your model and improve it further? Report the accuracy on the dev data here. If the score is now higher, explain why you think this is better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE-pMlbEU3oe"
      },
      "source": [
        "#### $\\color{blue}{\\text{Solution 5.2}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZBwI-sGH3Gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c57421bc-adff-44b3-8ec7-c823560e9039"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 53.3MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=2ff12e15b3fba206284f2c89b3f38114312a6019868d546fc50833d30f517d1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_HlOxn4Y2cr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5fcdb6ba543a4022a825cc9c33092168",
            "a61d4b05413548bb959f19cbe18ec4e0",
            "3db305e73b944c1190cb39401492d900",
            "052f92a0543b48669c29d809d35bbd93",
            "aa24a06ade054d82a74faf06ce48b9bd",
            "8d9d984a928342ed9f0e4cf1501c7895",
            "8ed78d9b8533470ca39833400f260d1e",
            "c0827c66b5d24223a48255e6889796ea",
            "bfc896e651a241f3a5358895bb723e1d",
            "4888cc20efeb46d597e602b1eae7a58d",
            "f9db44e9f7c0476cbe9ac8c990df4ed4",
            "9efc1d1874ef414080c15a060fe7f98b",
            "6850fd982a3b4cca8fb90a8c5b0d0665",
            "a484c6673db644769832fa3e55c4c0be",
            "683c4455d9a6409fa3232f97f621bc7e",
            "9b38a058067349cfa293dc9ff2fcd760",
            "0043719545de4b0b87be69b56e6b7404",
            "e0afaf4f3fda4188af044dc97378f66e",
            "56a75348d52d46b0818c10904a9556d7",
            "ebed889def87402d958c7f904259e82e",
            "71a503fbda8645c58f30ad9e2b3e61ab",
            "73e203b59cde424eab1d986be21d0940",
            "4e23c8eba6724fe9bdac9dfae0ccfeea",
            "7092c98c6ee348289c2dc8e3977f7a29",
            "72e1fb5e4f574da6ba9c30bd7e6f54bf",
            "aeab2f15d3eb4ea992be133ad03a0c4d",
            "b89569f48e434c7b9444a60b3705c672",
            "e196344fc50e4347a8889f501970cefc",
            "5b2044b467ea4ef7901d17e652ecfada",
            "e7581f3177bf4e2895ab544936c77f52",
            "6193f5ffc95447c2a52de28d1ddb21bf",
            "4aa32df0815a4424b520f400c5a0263e",
            "c5c31ab0a2004e09850f368bce424adf",
            "433efc1bc42b4391a57492e52482337d",
            "3a29299804594b4e8c01a9552eca71fe",
            "d6354fb3f56e4755a226b3f568cd51a7",
            "1be4668d4ffe40df9f41ebccab5f8610",
            "7f9ff0e9fd4b4cedb8abffd2f496c4ec",
            "e11a5dba97474cd3860c6163b5e7c096",
            "b51bce2b054248909a208b20c5461dd4"
          ]
        },
        "outputId": "a188f003-89dd-4d62-ce5f-67a715dc6038"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fcdb6ba543a4022a825cc9c33092168",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfc896e651a241f3a5358895bb723e1d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0043719545de4b0b87be69b56e6b7404",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72e1fb5e4f574da6ba9c30bd7e6f54bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5c31ab0a2004e09850f368bce424adf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5_Lg2S9dngm"
      },
      "source": [
        "def tokenization1(text): \n",
        "  indexed_tokens_list = []\n",
        "  segment_ids_list = []\n",
        "  for i in range(len(text)):\n",
        "    tokenized_text = tokenizer.tokenize(text[i])\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segment_ids = [1]*len(tokenized_text) \n",
        "    indexed_tokens_list.append(indexed_tokens)\n",
        "    segment_ids_list.append(segment_ids)\n",
        "  return indexed_tokens_list, segment_ids_list\n",
        "\n",
        "text = list(tsv_read['sentence'])\n",
        "labels = list(tsv_read['label'])\n",
        "indexed_tokens_list, segment_ids_list = tokenization1(text)\n",
        "\n",
        "val_text = list(val_tsv_read['sentence'])\n",
        "val_labels = list(val_tsv_read['label'])\n",
        "val_indexed_tokens_list, val_segment_ids_list = tokenization1(val_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7RtruDrGaNg"
      },
      "source": [
        "class LSTM_without_emb(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        \"\"\"\n",
        "        Implementation of recurrent neural network using\n",
        "        `nn.Linear` and `nn.Parameter`class\n",
        "        \"\"\"\n",
        "        super(LSTM_without_emb, self).__init__()\n",
        "        self.input_size = 768\n",
        "        self.hidden_size = d\n",
        "        self.output_size = 2\n",
        "        # i_t, c_t, f_t, o_t\n",
        "        self.W = nn.Parameter(torch.Tensor(self.input_size, self.hidden_size * 4))\n",
        "        self.U = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size * 4))\n",
        "        self.b = nn.Parameter(torch.Tensor(self.hidden_size * 4))\n",
        "\n",
        "        self.linear = nn.Linear(self.hidden_size, self.output_size, bias=True) \n",
        "\n",
        "        self.init_weights()\n",
        "                \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "         \n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
        "        # print(input_tensor.shape)\n",
        "        emb = input_tensor\n",
        "        batch_size = emb.shape[0]\n",
        "\n",
        "        h_t, c_t = (torch.zeros(batch_size, self.hidden_size).to(emb.device), \n",
        "                        torch.zeros(batch_size, self.hidden_size).to(emb.device))\n",
        "          \n",
        "        ds = self.hidden_size\n",
        "        for t in range(emb.shape[1]):\n",
        "            emb_t = emb[:, t, :]\n",
        "            gate = emb_t @ self.W + h_t @ self.U + self.b\n",
        "            i_t, f_t, g_t, o_t = (\n",
        "                torch.sigmoid(gate[:, :ds]), \n",
        "                torch.sigmoid(gate[:, ds:ds*2]),  \n",
        "                torch.tanh(gate[:, ds*2:ds*3]),\n",
        "                torch.sigmoid(gate[:, ds*3:]), \n",
        "            )\n",
        "            c_t = f_t * c_t + i_t * g_t\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        out = self.linear(h_t)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNkN4Iiw5tOa"
      },
      "source": [
        "# result_path = '/home/edlab/radhika/radhika_77/data/nlp/models/'\n",
        "result_path = '/content/drive/MyDrive/nlp/'\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "softmax = nn.Softmax(1) \n",
        "\n",
        "def train(model1, indexed_tokens_list, segment_ids_list, labels, val_indexed_tokens_list, val_segment_ids_list, val_labels, num_epochs = 12, file = None):\n",
        "    if (file != 'None'):\n",
        "      best_file = os.path.join(result_path, file)\n",
        "    model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
        "    model.eval()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "    best_acc = 0\n",
        "    best_acc_epoch = 0\n",
        "    \n",
        "    train_loss=[]\n",
        "    train_acc=[]\n",
        "    val_loss = []\n",
        "    val_acc=[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      epoch_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      epoch_acc = 0\n",
        "      for i in range(len(labels[:40000])):\n",
        "          with torch.no_grad():\n",
        "            tokens_tensor = torch.tensor([indexed_tokens_list[i]]); segments_tensor= torch.tensor([segment_ids_list[i]])\n",
        "            outputs = model(tokens_tensor, segments_tensor)\n",
        "            hidden_states = outputs[2]\n",
        "            token_embeddings = torch.stack(hidden_states, dim =0)\n",
        "            token_embeddings = torch.squeeze(token_embeddings, dim =1)\n",
        "            token_embeddings = token_embeddings.permute(1,0,2)\n",
        "            tokens_vec_sum = []\n",
        "            for token in token_embeddings:\n",
        "              sum_vec = torch.sum(token[-4:], dim=0)\n",
        "              tokens_vec_sum.append(sum_vec)\n",
        "          # print(data[i].shape)\n",
        "          input_tensor = torch.stack(tokens_vec_sum)\n",
        "          input_tensor = input_tensor.reshape(1, input_tensor.shape[0], input_tensor.shape[1])\n",
        "          label = torch.LongTensor([labels[i]])\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          logits = model1(input_tensor)\n",
        "          # print(logits.shape, label.shape)\n",
        "          loss = criterion(logits, label)\n",
        "          loss.backward(retain_graph=True) \n",
        "          optimizer.step()\n",
        "          _, predicted = torch.max(logits.data, 1)\n",
        "          total += label.size(0)\n",
        "          # print(predicted, label)\n",
        "          correct += (predicted == label).sum().item()\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "      epoch_acc = (100 * correct / total)\n",
        "      train_loss.append(round((epoch_loss / len(labels)), 2))\n",
        "      train_acc.append(round((epoch_acc),2))\n",
        "\n",
        "      with torch.no_grad():\n",
        "            model1.eval()\n",
        "            val_epoch_loss = 0\n",
        "            val_total = 0\n",
        "            val_correct = 0\n",
        "            epoch_val_acc = 0\n",
        "            for i in range(len(val_labels)):\n",
        "                with torch.no_grad():\n",
        "                  tokens_tensor = torch.tensor([val_indexed_tokens_list[i]]); segments_tensor= torch.tensor([val_segment_ids_list[i]])\n",
        "                  outputs = model(tokens_tensor, segments_tensor)\n",
        "                  hidden_states = outputs[2]\n",
        "                  token_embeddings = torch.stack(hidden_states, dim =0)\n",
        "                  token_embeddings = torch.squeeze(token_embeddings, dim =1)\n",
        "                  token_embeddings = token_embeddings.permute(1,0,2)\n",
        "                  tokens_vec_sum = []\n",
        "                  for token in token_embeddings:\n",
        "                    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "                    tokens_vec_sum.append(sum_vec)\n",
        "                input_tensor = torch.stack(tokens_vec_sum)\n",
        "                input_tensor = input_tensor.reshape(1, input_tensor.shape[0], input_tensor.shape[1])\n",
        "                label = torch.LongTensor([val_labels[i]])\n",
        "                logits = model1(input_tensor)\n",
        "                loss = criterion(logits, label)\n",
        "                _, predicted = torch.max(logits.data, 1)\n",
        "                val_total += label.size(0)\n",
        "                val_correct += (predicted == label).sum().item()\n",
        "                val_epoch_loss += loss.item()\n",
        "\n",
        "            val_loss.append(round((val_epoch_loss / len(val_labels)),2))\n",
        "            epoch_val_acc = (100 * val_correct / val_total)\n",
        "            val_acc.append(round((epoch_val_acc),2))\n",
        "      # print(\"epoch {}: Training Loss- {:.2f} , Val Loss- {:.2f} , Training Acc- {:.2f}, Val Acc- {:.2f}\".format(epoch, epoch_loss, val_epoch_loss, epoch_acc, epoch_val_acc))\n",
        "      if (epoch_val_acc >= best_acc):\n",
        "            best_acc = epoch_val_acc\n",
        "            best_acc_epoch = epoch\n",
        "            if (file!=None):\n",
        "              torch.save(model.state_dict(), best_file)         \n",
        "    return model1, train_loss, train_acc, val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf19fA-Iz8P4"
      },
      "source": [
        "def test(model, indexed_tokens_list, segment_ids_list, file = None):\n",
        "    if (file!=None):\n",
        "      best_file = os.path.join(result_path, file)\n",
        "      model.load_state_dict(torch.load(best_file))\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        test_total = 0\n",
        "        test_correct = 0\n",
        "        test_loss = 0\n",
        "        test_accuracy = 0\n",
        "        for i in range(len(labels)):\n",
        "            with torch.no_grad():\n",
        "              tokens_tensor = torch.tensor([indexed_tokens_list[i]]); segments_tensor= torch.tensor([segment_ids_list[i]])\n",
        "              outputs = model(tokens_tensor, segments_tensor)\n",
        "              hidden_states = outputs[2]\n",
        "              token_embeddings = torch.stack(hidden_states, dim =0)\n",
        "              token_embeddings = torch.squeeze(token_embeddings, dim =1)\n",
        "              token_embeddings = token_embeddings.permute(1,0,2)\n",
        "              tokens_vec_sum = []\n",
        "              for token in token_embeddings:\n",
        "                sum_vec = torch.sum(token[-4:], dim=0)\n",
        "                tokens_vec_sum.append(sum_vec)\n",
        "            # print(data[i].shape)\n",
        "            input_tensor = torch.stack(tokens_vec_sum)\n",
        "            input_tensor = input_tensor.reshape(1, input_tensor.shape[0], input_tensor.shape[1])\n",
        "            label = torch.LongTensor([labels[i]])\n",
        "            logits = model(input_tensor)\n",
        "            loss = criterion(logits, label)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            test_total += label.size(0)\n",
        "            test_correct += (predicted == label).sum().item()\n",
        "            test_loss += loss.item()\n",
        "        test_accuracy = round((100 * test_correct / test_total), 2)\n",
        "        print(\"Test loss: {}, test accuracy: {}\". format(round((test_loss / len(labels)),2), test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pupp9WU8ERQZ"
      },
      "source": [
        "d = 128\n",
        "num_epochs = 12\n",
        "model = LSTM_without_emb(d)\n",
        "model1, train_loss, train_acc, val_loss, val_acc = train(model, indexed_tokens_list, segment_ids_list, labels, val_indexed_tokens_list, val_segment_ids_list, val_labels, num_epochs, 'best_LSTM_without_emb.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xyiHfdDg8i1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902d99d2-63e0-472c-87b4-bff1afcffca4"
      },
      "source": [
        "test_text = list(test_tsv_read['sentence'])\n",
        "test_labels = list(test_tsv_read['label'])\n",
        "test_indexed_tokens_list, test_segment_ids_list = tokenization1(test_text)\n",
        "test(model1, indexed_tokens_list, segment_ids_list, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.91, test accuracy: 85.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQM7oX2Ztz_N"
      },
      "source": [
        "<font color='blue'>The model is trained for 10 epochs. The accuracy of the model is **85.62%** on the dev set. This model outperforms the baseline model, vanilla RNN, LSTM, LSTM with dropout.<font>\n",
        "\n",
        "<font color='blue'>This model outperforms the existing LSTM variants in (LSTM, LSTM with dropout in section 4). This is because of 2 reasons:\n",
        " \n",
        "1. Word vectors obtained from pretrained language models helps in getting embeddings for words that never appeared in the training set. So, **the issue of out-of-vocabulary is eliminated**. **Pre-trained language models provide us word embeddings for words it has not seen before or words which rarely occured in training set**. <font>\n",
        "2. The issue of language polysemy is eliminated. It recognizes **that a word may have more than one meaning depending on the context**. So it does not assign any single vector to a word. Instead, it computes the representation of a word by taking the entire sequence as an input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxmY-5tIthx8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}